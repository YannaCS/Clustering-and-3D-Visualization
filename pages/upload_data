import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import io

import utils

def show():
    """Display the upload data page"""
    st.header("Upload Your Dataset")
    
    # Instructions
    st.write("""
    Upload a CSV file with the following format:
    - The file should have at least 4 columns
    - The first three columns should contain your 3D data points (X1, X2, X3)
    - The last column should be named 'Class' containing ground truth class labels
    """)
    
    # Example data
    with st.expander("Show example data format"):
        example_data = pd.DataFrame({
            'X1': [1.2, 2.3, -1.5, 0.8, -0.5],
            'X2': [0.5, 1.1, -2.0, 0.3, -1.2],
            'X3': [0.8, 1.7, -0.9, 1.5, -0.7],
            'Class': [1, 1, 2, 1, 2]
        })
        st.dataframe(example_data)
        
        # Download example CSV
        csv = example_data.to_csv(index=False)
        st.download_button(
            label="Download Example CSV",
            data=csv,
            file_name="example_clustering_data.csv",
            mime="text/csv"
        )
    
    # File uploader
    uploaded_file = st.file_uploader("Choose a CSV file", type="csv")
    
    if uploaded_file is not None:
        try:
            # Load and process the uploaded data
            user_data = pd.read_csv(uploaded_file)
            
            # Display the first few rows
            st.subheader("Preview of uploaded data:")
            st.dataframe(user_data.head())
            
            # Validate the data
            validation_message = validate_data(user_data)
            
            if validation_message:
                st.error(validation_message)
            else:
                # Data processing options
                st.subheader("Data Processing Options")
                
                # Select feature columns
                all_columns = user_data.columns.tolist()
                default_feature_cols = all_columns[:3] if len(all_columns) >= 4 else all_columns
                
                feature_cols = st.multiselect(
                    "Select feature columns (exactly 3 required for 3D visualization)",
                    options=all_columns,
                    default=default_feature_cols[:3]
                )
                
                # Select class column
                class_col = st.selectbox(
                    "Select class/label column",
                    options=all_columns,
                    index=all_columns.index('Class') if 'Class' in all_columns else min(3, len(all_columns)-1)
                )
                
                # Validate selections
                if len(feature_cols) != 3:
                    st.error("Please select exactly 3 feature columns for 3D visualization.")
                elif class_col in feature_cols:
                    st.error("The class column cannot also be a feature column.")
                else:
                    # Create a new DataFrame with only the needed columns
                    analysis_data = user_data[feature_cols + [class_col]].copy()
                    
                    # Rename columns for consistency with the analysis functions
                    column_mapping = {
                        feature_cols[0]: 'X1',
                        feature_cols[1]: 'X2',
                        feature_cols[2]: 'X3',
                        class_col: 'Class'
                    }
                    analysis_data = analysis_data.rename(columns=column_mapping)
                    
                    # Show dataset statistics
                    with st.expander("Dataset Statistics"):
                        st.write(f"Number of samples: {len(analysis_data)}")
                        st.write(f"Number of classes: {analysis_data['Class'].nunique()}")
                        st.write(f"Class distribution: {analysis_data['Class'].value_counts().to_dict()}")
                    
                    # Run the clustering analysis when button is clicked
                    if st.button("Run Clustering Analysis"):
                        with st.spinner("Running clustering analysis... This may take a moment."):
                            # Run the clustering analysis
                            results, error = utils.run_clustering_analysis(analysis_data)
                            
                            if error:
                                st.error(error)
                            else:
                                st.success("Analysis complete!")
                                display_results(results)
        
        except Exception as e:
            st.error(f"An error occurred: {str(e)}")
            st.write("Please ensure your CSV file is properly formatted.")

def validate_data(df):
    """Validate the uploaded dataset"""
    # Check if the dataframe has at least 4 columns
    if len(df.columns) < 4:
        return "The dataset must have at least 4 columns (3 for features and 1 for class labels)."
    
    # Check if 'Class' column exists
    if 'Class' not in df.columns:
        return "The dataset must contain a column named 'Class' with ground truth labels, or you must select a class column in the options below."
    
    # Check for missing values
    if df.isnull().values.any():
        return "The dataset contains missing values. Please clean your data before uploading."
    
    # Check if there are at least 2 unique classes
    if 'Class' in df.columns and df['Class'].nunique() < 2:
        return "The dataset must contain at least 2 different classes for meaningful clustering evaluation."
    
    # All checks passed
    return None

def display_results(results):
    """Display the results of clustering analysis"""
    # Create tabs for organizing results
    tabs = st.tabs(["Optimal Clusters", "3D Visualization", "Performance Metrics", "Detailed Results"])
    
    # Optimal Clusters tab
    with tabs[0]:
        st.subheader("Determining the Optimal Number of Clusters")
        st.pyplot(results['k_plot'])
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Best K for K-means", results['best_k_kmeans'])
        with col2:
            st.metric("Best K for Hierarchical", results['best_k_hierarchical'])
        with col3:
            st.metric("Chosen K for Analysis", results['best_k'])
        
        with st.expander("Explanation of Metrics"):
            st.write("""
            - **Elbow Plot**: Shows the sum of squared distances from each point to its assigned center. 
              The optimal K value is where the curve begins to flatten (the "elbow").
            - **Silhouette Score**: Measures how similar an object is to its own cluster compared to other clusters.
              Values range from -1 to 1, with higher values indicating better clustering.
            - **Calinski-Harabasz (CH) Score**: Ratio of between-cluster dispersion to within-cluster dispersion.
              Higher values indicate better-defined clusters.
            """)
    
    # 3D Visualization tab
    with tabs[1]:
        st.subheader("3D Visualization of Clusters")
        st.plotly_chart(results['comparison_fig'], use_container_width=True)
        
        with st.expander("Visualization Explanation"):
            st.write("""
            - **Left**: Original class labels from the dataset
            - **Middle**: Clusters identified by K-means algorithm
            - **Right**: Clusters identified by Hierarchical clustering algorithm
            
            Interact with the plots by:
            - Rotating: Click and drag
            - Zooming: Scroll or use the zoom tools
            - Panning: Right-click and drag
            """)
    
    # Performance Metrics tab
    with tabs[2]:
        st.subheader("Performance Comparison")
        
        # Performance comparison at best K
        st.pyplot(results['performance_fig'])
        
        # Performance across all K values
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("K-means Performance Across K Values")
            st.pyplot(results['kmeans_metrics_fig'])
        
        with col2:
            st.subheader("Hierarchical Performance Across K Values")
            st.pyplot(results['hierarchical_metrics_fig'])
        
        with st.expander("Metrics Explanation"):
            st.write("""
            - **Precision (Pr)**: The ratio of true positive pairs to all pairs predicted to be in the same cluster
            - **Recall**: The ratio of true positive pairs to all pairs that should be in the same cluster
            - **Jaccard Index (J)**: The size of the intersection divided by the size of the union of the sample sets
            - **Rand Index**: The percentage of correct decisions (true positives and true negatives)
            - **Fowlkes-Mallows Score (FM)**: Geometric mean of precision and recall
            """)
    
    # Detailed Results tab
    with tabs[3]:
        st.subheader("Detailed Performance Metrics")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("K-means Performance for all K values:")
            st.dataframe(results['kmeans_performances'])
        
        with col2:
            st.write("Hierarchical Clustering Performance for all K values:")
            st.dataframe(results['hierarchical_performances'])